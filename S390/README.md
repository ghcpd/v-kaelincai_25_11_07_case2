# Evaluation of UI/UX Improvement (Modal to Wizard + Lazy Loading)

This repository contains two projects demonstrating a UI/UX improvement for a task creation flow:

- Project_A_PreImprove_UI: modal-based form that eagerly loads tags, members, and attachments and places title/due later in the form. Produces slow perceived load and poor field visibility.
- Project_B_PostImprove_UI: wizard-based flow with lazy loading of heavy datasets and prioritization of title/due in first step.

Each project includes an HTML/JS frontend, a Flask server that simulates API endpoints (with optional delays and dataset sizes), and Playwright-based automated tests that measure performance, visibility, and lazy loading.

High-level steps to run:
1. Run the all-in-one runner from the repo root:
   - Windows: `run_all.sh` (double-click or run from cmd)
2. Or run individual project tests:
   - `cd Project_A_PreImprove_UI` then `setup.sh` then `run_tests.sh 1`
   - `cd Project_B_PostImprove_UI` then `setup.sh` then `run_tests.sh 1`

Artifacts:
- Project-specific `results/results_pre.json` and `results/results_post.json` (copied to `shared/results`)
- `compare_report.md` in repo root generated by `shared/scripts/generate_report.py`
- Screenshots saved under each project's `screenshots/` folder.

Limitations and notes:
- This is a simulated demo. Real user devices, browsers, and networks may show more variability.
- Use A/B testing and telemetry to validate in production progressively.
- Accessibility checks are minimal â€” production rollout should conduct deeper audits with screen readers and keyboard-only tests.

Recommended rollout:
- A/B test with gradual rollout and telemetry to capture task creation success rate, time-to-create, and field usage.
- Monitor errors, timeouts, and accessibility metrics.

